{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "import matplotlib\n",
    "matplotlib.use('Agg') \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "\n",
    "from util import utils as data_utils\n",
    "\n",
    "%pylab inline\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'Blues'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "json_file = './cifar_results/noise/bootstrap_var_lr_001/checkpoint_200.json'\n",
    "FDIR = os.path.dirname(json_file)\n",
    "NUM_CLASSIFY = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Plot gradients norms for the entire learning process\n",
    "grads_json_filename = os.path.join(FDIR, 'model_grads.json')\n",
    "grads = [[], [], []]\n",
    "grads_key = ['max_grad_w1_16', 'max_grad_w1_32', 'max_grad_w1_64']\n",
    "if os.path.exists(grads_json_filename):\n",
    "    with open(grads_json_filename, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "        for i, k in enumerate(grads_key):\n",
    "            if data[0].get(k, None) is None:\n",
    "                continue\n",
    "            for batch_grads in data:\n",
    "                grads[i].append(batch_grads[k])\n",
    "\n",
    "def plot_grads(grads, title, x_label, y_label, figsize=(10, 8)):\n",
    "    plt.figure(figsize=figsize)\n",
    "    # plt.subplot(2, 1, 1)\n",
    "    plt.plot(grads)\n",
    "    plt.title(title)\n",
    "    plt.ylabel(y_label)\n",
    "    plt.xlabel(x_label)\n",
    "    \n",
    "for i, g in enumerate(grads):\n",
    "    if len(g) > 0:\n",
    "        plot_grads(g, grads_key[i], 'iterations', grads_key[i])\n",
    "        # pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(json_file, 'r') as fp:\n",
    "    data = json.load(fp)\n",
    "# Loss history might not be of equal length.\n",
    "train_loss_hist = data['train_loss_history']\n",
    "val_loss_hist = data['val_loss_history']\n",
    "\n",
    "# pdb.set_trace()\n",
    "def plot_loss_hist(loss_hist, title,):\n",
    "    plt.figure(figsize=(5,4))\n",
    "    plt.subplot(1, 1, 1)\n",
    "    plt.plot(loss_hist)\n",
    "    plt.title(title)  # Train Loss\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('time')\n",
    "    plt.show()\n",
    "    \n",
    "plot_loss_hist(train_loss_hist, 'Train Loss')\n",
    "plot_loss_hist(val_loss_hist, 'Val loss')\n",
    "\n",
    "if data.get('crit1_loss_history', None) is not None:\n",
    "    plot_loss_hist(data['crit1_loss_history'], 'Target criterion loss')\n",
    "\n",
    "if data.get('crit2_loss_history', None) is not None and \\\n",
    "    len(data['crit2_loss_history']) > 0:\n",
    "    plot_loss_hist(data['crit2_loss_history'], 'Pred criterion loss')\n",
    "\n",
    "if data.get('pred_loss_history', None) is not None and \\\n",
    "    len(data['pred_loss_history']) > 0:\n",
    "    plot_loss_hist(data['pred_loss_history'], 'Total Pred loss (beta*t + (1-beta)*p)')    \n",
    "\n",
    "if data.get('beta_loss_history', None) is not None and \\\n",
    "    len(data['beta_loss_history']) > 0:\n",
    "    plot_loss_hist(data['beta_loss_history'], 'Beta loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if data.get('KL_loss_history', None) is not None:\n",
    "    # Loss history might not be of equal length.\n",
    "    KL_loss_hist = data['KL_loss_history']\n",
    "\n",
    "    plt.figure(figsize=(10,8))\n",
    "    plt.plot(KL_loss_hist)\n",
    "    plt.title('KL loss')\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('time')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_conf(json_file, num_classes=26, json_key='conf'):\n",
    "    with open(json_file, 'r') as fp:\n",
    "        data = json.load(fp)\n",
    "        conf = data.get(json_key, None)\n",
    "    if conf is None:\n",
    "        return\n",
    "    # c1 = conf.split('\\n')[1].split(\"]\")[0].split(\"[ \")[1].split(\" \")\n",
    "    c1 = conf.split('\\n')\n",
    "    # print(c1)\n",
    "    conf_mat, row_idx = np.zeros((num_classes, num_classes)), 0\n",
    "    for i in c1:\n",
    "        #pdb.set_trace()\n",
    "        is_conf_row = False\n",
    "        if ']' in i and '[[' in i:\n",
    "            val = i.split(']')[0].split('[[')[1].split(' ')\n",
    "            is_conf_row = True\n",
    "        elif ']' in i and '[' in i:\n",
    "            val = i.split(']')[0].split('[')[1].split(' ')\n",
    "            is_conf_row = True\n",
    "        if is_conf_row:\n",
    "            col_idx = 0\n",
    "            for v in val:\n",
    "                if not len(v):\n",
    "                    continue\n",
    "                try:\n",
    "                    conf_mat[row_idx, col_idx] = int(v)\n",
    "                    col_idx = col_idx + 1\n",
    "                except:\n",
    "                    continue\n",
    "            row_idx = row_idx + 1\n",
    "    \n",
    "    assert(row_idx == num_classes)\n",
    "    conf_mat = conf_mat.astype(int)\n",
    "    fdir = os.path.dirname(json_file)\n",
    "    json_name = os.path.basename(json_file)[:-5]\n",
    "    conf_file_name = fdir + '/' + 'conf_' + json_name + '.txt'\n",
    "    np.savetxt(conf_file_name, conf_mat, fmt='%d', delimiter=', ')\n",
    "    return conf_mat\n",
    "\n",
    "\n",
    "def plot_conf(norm_conf):\n",
    "  # Plot using seaborn\n",
    "  # (this is style I used for ResNet matrix)\n",
    "  plt.figure(figsize=(10,6))\n",
    "  df_cm = pd.DataFrame(norm_conf)\n",
    "  sns.heatmap(df_cm, annot=True, cmap=\"Blues\")\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sorted_checkpoints(fdir):\n",
    "    # Checkpoint files are named as 'checkpoint_%d.json'\n",
    "    checkpoint_map = {}\n",
    "    for f in os.listdir(fdir):\n",
    "        if f.endswith('json') and f.startswith('checkpoint'):\n",
    "            checkpoint_num = int(f.split('checkpoint_')[-1].split('.')[0])\n",
    "            checkpoint_map[checkpoint_num] = f\n",
    "    sorted_checkpoints = []\n",
    "    for k in sorted(checkpoint_map.keys()):\n",
    "        v = checkpoint_map[k]\n",
    "        sorted_checkpoints.append(v)\n",
    "    return sorted_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def best_f_scores(fdir, num_classes=5): \n",
    "    best_checkpoints = [None, None, None]\n",
    "    best_3_fscores = [0, 0, 0]\n",
    "    best_confs = [np.array(()), np.array(()), np.array(())]\n",
    "    f1_weight_list = [1.0] * num_classes\n",
    "    f1_weights = np.array(f1_weight_list)\n",
    "    sorted_checkpoint_files = get_sorted_checkpoints(fdir)\n",
    "    for f in sorted_checkpoint_files:\n",
    "        json_file = fdir + '/' + f\n",
    "        conf = get_conf(json_file, num_classes, json_key='val_conf')\n",
    "        norm_conf = data_utils.normalize_conf(conf)\n",
    "        f1 = data_utils.get_f1_score(conf, f1_weights)\n",
    "        kappa = data_utils.computeKappa(conf)\n",
    "        wt_f1 = data_utils.computeWeightedF1(conf)\n",
    "        print('file: {}, f1: {:.3f}, kappa: {:.3f}, weighted-F1: {:.3f}'.format(\n",
    "                f, f1, kappa, wt_f1))\n",
    "        plot_conf(norm_conf)\n",
    "        max_idx = -1\n",
    "        for i in range(len(best_3_fscores)):\n",
    "            if best_3_fscores[i] > f1:\n",
    "                break\n",
    "            max_idx = i\n",
    "        for j in range(max_idx):\n",
    "            best_3_fscores[j] = best_3_fscores[j+1]\n",
    "            best_confs[j] = best_confs[j+1]\n",
    "            best_checkpoints[j] = best_checkpoints[j+1]\n",
    "\n",
    "        best_3_fscores[max_idx] = f1\n",
    "        best_confs[max_idx] = conf\n",
    "        best_checkpoints[max_idx] = f\n",
    "\n",
    "    return best_3_fscores, best_confs, best_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_train_conf(fdir, num_classes=5):\n",
    "    sorted_checkpoint_files = get_sorted_checkpoints(fdir)\n",
    "    if len(sorted_checkpoint_files) > 0:\n",
    "        last_checkpoint = sorted_checkpoint_files[-1]\n",
    "        json_file = fdir + '/' + last_checkpoint\n",
    "        conf = get_conf(json_file, num_classes=num_classes, json_key='train_conf')\n",
    "        print(conf)\n",
    "        norm_conf = data_utils.normalize_conf(conf)\n",
    "        f1_weight_list = [1.0] * num_classes\n",
    "        f1_weights = np.array(f1_weight_list)\n",
    "        f1 = data_utils.get_f1_score(conf, f1_weights)\n",
    "        kappa = data_utils.computeKappa(conf)\n",
    "        wt_f1 = data_utils.computeWeightedF1(conf)\n",
    "        print('file: {}, f1: {:.3f}, kappa: {:.3f}, weighted-F1: {:.3f}'.format(\n",
    "            f, f1, kappa, wt_f1))\n",
    "        plot_conf(norm_conf)\n",
    "\n",
    "plot_train_conf(FDIR, num_classes=NUM_CLASSIFY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "best_f_scores(FDIR, num_classes=NUM_CLASSIFY)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
